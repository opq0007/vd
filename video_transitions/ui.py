"""
è§†é¢‘è½¬åœºæ•ˆæœçš„Gradioç•Œé¢
"""

import gradio as gr
import asyncio
import torch
import numpy as np
from pathlib import Path
from typing import Tuple, Optional, Dict, Any
import time

from video_transitions import TransitionFactory
from video_transitions.base import BaseTransition


class VideoTransitionUI:
    """è§†é¢‘è½¬åœºæ•ˆæœUIç±»"""
    
    def __init__(self):
        self.transition_factory = TransitionFactory()
        self.available_transitions = self.transition_factory.get_available_transitions()
        self.current_transition = None
        
    def create_interface(self) -> gr.Blocks:
        """åˆ›å»ºè½¬åœºæ•ˆæœç•Œé¢"""
        
        with gr.Blocks(title="è§†é¢‘è½¬åœºç‰¹æ•ˆ") as interface:
            gr.Markdown("# ğŸ¬ è§†é¢‘è½¬åœºç‰¹æ•ˆ")
            gr.Markdown("ä¸ºå›¾ç‰‡æˆ–è§†é¢‘ä¹‹é—´æ·»åŠ ä¸“ä¸šçš„è½¬åœºæ•ˆæœ")
            
            with gr.Row():
                with gr.Column(scale=2):
                    # è¾“å…¥æ–‡ä»¶é€‰æ‹©
                    gr.Markdown("### ğŸ“ è¾“å…¥æ–‡ä»¶")
                    with gr.Row():
                        video1_input = gr.File(
                            label="ç¬¬ä¸€ä¸ªè§†é¢‘/å›¾ç‰‡",
                            file_types=[".mp4", ".avi", ".mov", ".png", ".jpg", ".jpeg"]
                        )
                        video2_input = gr.File(
                            label="ç¬¬äºŒä¸ªè§†é¢‘/å›¾ç‰‡", 
                            file_types=[".mp4", ".avi", ".mov", ".png", ".jpg", ".jpeg"]
                        )
                
                with gr.Column(scale=1):
                    # é¢„è§ˆåŒºåŸŸ
                    gr.Markdown("### ğŸ‘ï¸ é¢„è§ˆ")
                    preview1 = gr.Image(label="é¢„è§ˆ1", type="numpy")
                    preview2 = gr.Image(label="é¢„è§ˆ2", type="numpy")
            
            # è½¬åœºæ•ˆæœé€‰æ‹©
            gr.Markdown("### ğŸ¨ è½¬åœºæ•ˆæœ")
            
            with gr.Row():
                # è·å–è½¬åœºæ•ˆæœåˆ†ç±»
                categories = self._get_categories()
                category_dropdown = gr.Dropdown(
                    label="æ•ˆæœåˆ†ç±»",
                    choices=list(categories.keys()),
                    value="Basic"
                )
                
                transition_dropdown = gr.Dropdown(
                    label="è½¬åœºæ•ˆæœ",
                    choices=self._get_transitions_by_category("Basic"),
                    value="crossfade"
                )
            
            # å½“åˆ†ç±»æ”¹å˜æ—¶æ›´æ–°è½¬åœºæ•ˆæœåˆ—è¡¨
            category_dropdown.change(
                fn=self._update_transitions,
                inputs=[category_dropdown],
                outputs=[transition_dropdown]
            )
            
            # å‚æ•°é…ç½®åŒºåŸŸ
            gr.Markdown("### âš™ï¸ å‚æ•°é…ç½®")
            
            with gr.Row():
                with gr.Column():
                    # åŸºç¡€å‚æ•°
                    total_frames = gr.Slider(
                        label="è½¬åœºå¸§æ•°",
                        minimum=4,
                        maximum=300,
                        value=30,
                        step=1
                    )
                    fps = gr.Slider(
                        label="å¸§ç‡ (FPS)",
                        minimum=15,
                        maximum=60,
                        value=30,
                        step=1
                    )
                    width = gr.Slider(
                        label="è¾“å‡ºå®½åº¦",
                        minimum=320,
                        maximum=1920,
                        value=640,
                        step=32
                    )
                    height = gr.Slider(
                        label="è¾“å‡ºé«˜åº¦", 
                        minimum=240,
                        maximum=1080,
                        value=640,
                        step=32
                    )
                
                with gr.Column():
                    # åŠ¨æ€å‚æ•°åŒºåŸŸ
                    dynamic_params = gr.Column()
            
            # å½“è½¬åœºæ•ˆæœæ”¹å˜æ—¶æ›´æ–°å‚æ•°
            transition_dropdown.change(
                fn=self._update_params,
                inputs=[transition_dropdown],
                outputs=[dynamic_params]
            )
            
            # ç”ŸæˆæŒ‰é’®å’Œè¿›åº¦
            with gr.Row():
                generate_btn = gr.Button("ğŸ¬ ç”Ÿæˆè½¬åœºè§†é¢‘", variant="primary")
                progress_bar = gr.Progress()
                status_text = gr.Textbox(label="çŠ¶æ€", interactive=False)
            
            # è¾“å‡ºåŒºåŸŸ
            gr.Markdown("### ğŸ“¤ è¾“å‡ºç»“æœ")
            with gr.Row():
                output_video = gr.Video(label="è½¬åœºè§†é¢‘")
                download_btn = gr.DownloadButton(
                    label="ğŸ’¾ ä¸‹è½½è§†é¢‘",
                    visible=False
                )
            
            # ç»‘å®šäº‹ä»¶
            video1_input.change(
                fn=self._update_preview,
                inputs=[video1_input],
                outputs=[preview1]
            )
            
            video2_input.change(
                fn=self._update_preview,
                inputs=[video2_input],
                outputs=[preview2]
            )
            
            generate_btn.click(
                fn=self.generate_transition,
                inputs=[
                    video1_input,
                    video2_input,
                    transition_dropdown,
                    total_frames,
                    fps,
                    width,
                    height
                ],
                outputs=[output_video, download_btn, status_text]
            )
        
        return interface
    
    def _get_categories(self) -> Dict[str, list]:
        """è·å–è½¬åœºæ•ˆæœåˆ†ç±»"""
        categories = {}
        for name, info in self.available_transitions.items():
            category = info.get('category', 'General')
            if category not in categories:
                categories[category] = []
            categories[category].append(name)
        return categories
    
    def _get_transitions_by_category(self, category: str) -> list:
        """æ ¹æ®åˆ†ç±»è·å–è½¬åœºæ•ˆæœ"""
        transitions = []
        for name, info in self.available_transitions.items():
            if info.get('category', 'General') == category:
                transitions.append(name)
        return transitions
    
    def _update_transitions(self, category: str) -> gr.Dropdown:
        """æ›´æ–°è½¬åœºæ•ˆæœåˆ—è¡¨"""
        transitions = self._get_transitions_by_category(category)
        return gr.Dropdown(choices=transitions, value=transitions[0] if transitions else None)
    
    def _update_params(self, transition_name: str) -> gr.Column:
        """æ›´æ–°å‚æ•°é…ç½®ç•Œé¢"""
        params_info = self.transition_factory.get_transition_params(transition_name)
        
        with gr.Column() as param_col:
            for param_name, param_config in params_info.items():
                if param_name in ['total_frames', 'fps', 'width', 'height']:
                    continue  # è·³è¿‡åŸºç¡€å‚æ•°
                
                param_type = param_config.get('type', 'string')
                default_value = param_config.get('default')
                description = param_config.get('description', '')
                
                if param_type == 'choice':
                    gr.Dropdown(
                        label=description,
                        choices=param_config.get('options', []),
                        value=default_value
                    )
                elif param_type == 'int':
                    gr.Slider(
                        label=description,
                        minimum=param_config.get('min', 0),
                        maximum=param_config.get('max', 100),
                        value=default_value,
                        step=1
                    )
                elif param_type == 'float':
                    gr.Slider(
                        label=description,
                        minimum=param_config.get('min', 0.0),
                        maximum=param_config.get('max', 1.0),
                        value=default_value,
                        step=param_config.get('step', 0.1)
                    )
                elif param_type == 'boolean':
                    gr.Checkbox(
                        label=description,
                        value=default_value
                    )
                elif param_type == 'string':
                    gr.Textbox(
                        label=description,
                        value=default_value
                    )
        
        return param_col
    
    def _update_preview(self, file_path: str) -> Optional[np.ndarray]:
        """æ›´æ–°é¢„è§ˆå›¾ç‰‡"""
        if not file_path:
            return None
        
        try:
            from PIL import Image
            if file_path.lower().endswith(('.png', '.jpg', '.jpeg')):
                # å›¾ç‰‡æ–‡ä»¶ç›´æ¥æ˜¾ç¤º
                image = Image.open(file_path)
                return np.array(image)
            else:
                # è§†é¢‘æ–‡ä»¶æ˜¾ç¤ºç¬¬ä¸€å¸§
                import cv2
                cap = cv2.VideoCapture(file_path)
                ret, frame = cap.read()
                cap.release()
                if ret:
                    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                    return frame
        except Exception as e:
            print(f"é¢„è§ˆæ›´æ–°å¤±è´¥: {e}")
        
        return None
    
    async def generate_transition(
        self,
        video1_path: str,
        video2_path: str,
        transition_name: str,
        total_frames: int,
        fps: int,
        width: int,
        height: int,
        progress=gr.Progress()
    ) -> Tuple[Optional[str], Optional[gr.DownloadButton], str]:
        """ç”Ÿæˆè½¬åœºè§†é¢‘"""
        
        if not video1_path or not video2_path:
            return None, gr.DownloadButton(visible=False), "è¯·é€‰æ‹©ä¸¤ä¸ªè¾“å…¥æ–‡ä»¶"
        
        if not transition_name:
            return None, gr.DownloadButton(visible=False), "è¯·é€‰æ‹©è½¬åœºæ•ˆæœ"
        
        try:
            status = "å¼€å§‹ç”Ÿæˆè½¬åœºè§†é¢‘..."
            progress(0.1, desc=status)
            
            # åŠ è½½è§†é¢‘/å›¾ç‰‡
            video1_tensor = await self._load_media(video1_path, width, height)
            video2_tensor = await self._load_media(video2_path, width, height)
            
            progress(0.2, desc="åª’ä½“æ–‡ä»¶åŠ è½½å®Œæˆ")
            
            # åˆ›å»ºè½¬åœºæ•ˆæœå®ä¾‹
            transition = self.transition_factory.create_transition(transition_name)
            
            progress(0.3, desc="å¼€å§‹åº”ç”¨è½¬åœºæ•ˆæœ")
            
            # åº”ç”¨è½¬åœºæ•ˆæœ
            result_tensor = await transition.apply_transition(
                video1_tensor,
                video2_tensor,
                total_frames=total_frames,
                fps=fps,
                width=width,
                height=height
            )
            
            progress(0.8, desc="è½¬åœºæ•ˆæœåº”ç”¨å®Œæˆ")
            
            # ä¿å­˜è§†é¢‘
            output_path = await self._save_video(result_tensor, fps, width, height)
            
            progress(1.0, desc="è½¬åœºè§†é¢‘ç”Ÿæˆå®Œæˆ")
            
            # åˆ›å»ºä¸‹è½½æŒ‰é’®
            download_btn = gr.DownloadButton(
                label="ğŸ’¾ ä¸‹è½½è§†é¢‘",
                value=output_path,
                visible=True
            )
            
            return output_path, download_btn, "è½¬åœºè§†é¢‘ç”ŸæˆæˆåŠŸï¼"
            
        except Exception as e:
            print(f"è½¬åœºç”Ÿæˆå¤±è´¥: {e}")
            return None, gr.DownloadButton(visible=False), f"ç”Ÿæˆå¤±è´¥: {str(e)}"
    
    async def _load_media(self, file_path: str, width: int, height: int) -> torch.Tensor:
        """åŠ è½½åª’ä½“æ–‡ä»¶ï¼ˆè§†é¢‘æˆ–å›¾ç‰‡ï¼‰"""
        file_path = Path(file_path)
        
        if file_path.suffix.lower() in ['.png', '.jpg', '.jpeg']:
            # åŠ è½½å›¾ç‰‡
            from PIL import Image
            image = Image.open(file_path)
            image = image.resize((width, height))
            
            # è½¬æ¢ä¸ºtensor
            numpy_array = np.array(image)
            if numpy_array.max() > 1.0:
                numpy_array = numpy_array.astype(np.float32) / 255.0
            
            tensor = torch.from_numpy(numpy_array)
            return tensor.unsqueeze(0)  # æ·»åŠ batchç»´åº¦
            
        else:
            # åŠ è½½è§†é¢‘
            import cv2
            cap = cv2.VideoCapture(str(file_path))
            frames = []
            
            while True:
                ret, frame = cap.read()
                if not ret:
                    break
                
                # è°ƒæ•´å°ºå¯¸
                frame = cv2.resize(frame, (width, height))
                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                
                # è½¬æ¢ä¸ºtensor
                numpy_array = frame.astype(np.float32) / 255.0
                tensor = torch.from_numpy(numpy_array)
                frames.append(tensor)
            
            cap.release()
            
            if not frames:
                raise ValueError("æ— æ³•ä»è§†é¢‘æ–‡ä»¶ä¸­è¯»å–å¸§")
            
            return torch.stack(frames)
    
    async def _save_video(
        self,
        tensor: torch.Tensor,
        fps: int,
        width: int,
        height: int
    ) -> str:
        """ä¿å­˜è§†é¢‘æ–‡ä»¶"""
        import cv2
        from datetime import datetime
        from utils.video_utils import VideoUtils
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        output_dir = Path("output")
        output_dir.mkdir(exist_ok=True)
        
        # ç”Ÿæˆæ–‡ä»¶å
        timestamp = datetime.now().strftime("%Y%m%d-%H%M%S")
        output_path = output_dir / f"transition_{timestamp}.mp4"
        
        # ä½¿ç”¨è§†é¢‘å·¥å…·ç±»åˆ›å»ºå†™å…¥å™¨
        out = VideoUtils.create_video_writer(output_path, width, height, fps)
        
        if out is None:
            raise RuntimeError(f"æ— æ³•åˆ›å»ºè§†é¢‘å†™å…¥å™¨: {output_path}")
        
        # å†™å…¥å¸§
        for i in range(tensor.shape[0]):
            frame = tensor[i].cpu().numpy()
            frame = (frame * 255).astype(np.uint8)
            frame_bgr = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)
            out.write(frame_bgr)
        
        out.release()
        
        return str(output_path)