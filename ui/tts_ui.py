"""
è¯­éŸ³åˆæˆ UI ç»„ä»¶

æä¾› VoxCPM-1.5 ONNX è¯­éŸ³åˆæˆç•Œé¢ã€‚
"""

import gradio as gr
from typing import Tuple, Optional

from modules.tts_onnx_module import tts_onnx_module
from utils.logger import Logger


def create_tts_interface() -> gr.Blocks:
    """
    åˆ›å»ºè¯­éŸ³åˆæˆç•Œé¢

    Returns:
        gr.Blocks: Gradio ç•Œé¢å—
    """
    with gr.Blocks() as tts_interface:
        gr.Markdown("## ğŸ¤ VoxCPM-1.5 è¯­éŸ³åˆæˆ (ONNX)")
        gr.Markdown("ä½¿ç”¨ VoxCPM-1.5 ONNX æ¨¡å‹è¿›è¡Œé«˜è´¨é‡è¯­éŸ³åˆæˆï¼Œæ”¯æŒ 44.1kHz éŸ³é¢‘ï¼Œæ”¯æŒå‚è€ƒéŸ³é¢‘å…‹éš†å£°éŸ³")

        with gr.Row():
            with gr.Column():
                # è¾“å…¥åŒºåŸŸ
                gr.Markdown("### ğŸ“ è¾“å…¥æ–‡æœ¬")
                text_input = gr.Textbox(
                    value="ä½ å¥½ï¼Œè¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ–‡æœ¬ã€‚",
                    label="ç›®æ ‡æ–‡æœ¬",
                    placeholder="è¯·è¾“å…¥è¦åˆæˆçš„æ–‡æœ¬...",
                    lines=3
                )

                gr.Markdown("### ğŸµ å‚è€ƒéŸ³é¢‘ï¼ˆå¯é€‰ï¼‰")

                with gr.Row():
                    ref_input_type = gr.Radio(
                        choices=["ä¸Šä¼ æ–‡ä»¶", "è·¯å¾„æ–¹å¼", "é¢„ç¼–ç ç‰¹å¾"],
                        value="ä¸Šä¼ æ–‡ä»¶",
                        label="å‚è€ƒéŸ³é¢‘è¾“å…¥æ–¹å¼"
                    )

                # æŸ¥çœ‹æ‰€æœ‰ç‰¹å¾æŒ‰é’®
                with gr.Row():
                    list_features_btn = gr.Button("ğŸ“‹ æŸ¥çœ‹æ‰€æœ‰ç‰¹å¾ ID", variant="secondary", size="sm")

                # ä¸Šä¼ æ–‡ä»¶é€‰é¡¹
                with gr.Column(visible=True) as upload_col:
                    prompt_wav_upload = gr.Audio(
                        sources=["upload", "microphone"],
                        type="filepath",
                        label="å‚è€ƒéŸ³é¢‘ - ä¸Šä¼ æˆ–å½•åˆ¶ä¸€æ®µéŸ³é¢‘ä½œä¸ºå£°éŸ³å‚è€ƒ"
                    )
                    save_ref_btn = gr.Button("ğŸ’¾ ä¿å­˜ä¸ºé¢„ç¼–ç ç‰¹å¾", variant="secondary", size="sm")
                    feat_id_input = gr.Textbox(
                        label="ç‰¹å¾ ID",
                        placeholder="è¾“å…¥ç‰¹å¾ ID ä»¥ä¿å­˜æˆ–ä½¿ç”¨é¢„ç¼–ç ç‰¹å¾"
                    )

                # è·¯å¾„æ–¹å¼é€‰é¡¹
                with gr.Column(visible=False) as path_col:
                    prompt_wav_path = gr.Textbox(
                        label="å‚è€ƒéŸ³é¢‘è·¯å¾„",
                        placeholder="è¯·è¾“å…¥éŸ³é¢‘æ–‡ä»¶è·¯å¾„æˆ–URL"
                    )

                # é¢„ç¼–ç ç‰¹å¾é€‰é¡¹
                with gr.Column(visible=False) as feat_col:
                    feat_id_select = gr.Textbox(
                        label="ç‰¹å¾ ID",
                        placeholder="è¾“å…¥å·²ä¿å­˜çš„ç‰¹å¾ ID"
                    )

                with gr.Row():
                    prompt_text = gr.Textbox(
                        value="",
                        label="å‚è€ƒæ–‡æœ¬ - å¯é€‰ï¼šå‚è€ƒéŸ³é¢‘å¯¹åº”çš„æ–‡æœ¬å†…å®¹",
                        placeholder="å¦‚æœä¸Šä¼ äº†å‚è€ƒéŸ³é¢‘ï¼Œå¯ä»¥è¾“å…¥å¯¹åº”çš„æ–‡æœ¬..."
                    )

                generate_btn = gr.Button("ğŸ¬ ç”Ÿæˆè¯­éŸ³", variant="primary")

            with gr.Column():
                # å‚æ•°é…ç½®åŒºåŸŸ
                gr.Markdown("### âš™ï¸ å‚æ•°é…ç½®")

                cfg_value = gr.Slider(
                    minimum=1.0,
                    maximum=3.0,
                    value=2.0,
                    step=0.1,
                    label="CFGå€¼ï¼ˆå¼•å¯¼å¼ºåº¦ï¼‰- æ§åˆ¶ç”Ÿæˆè¯­éŸ³ä¸ç›®æ ‡æ–‡æœ¬çš„åŒ¹é…ç¨‹åº¦"
                )

                inference_timesteps = gr.Slider(
                    minimum=4,
                    maximum=30,
                    value=5,
                    step=1,
                    label="æ¨ç†æ­¥æ•° - å½±å“ç”Ÿæˆè´¨é‡å’Œé€Ÿåº¦çš„å¹³è¡¡ï¼ˆé»˜è®¤ 5ï¼‰"
                )

                max_len = gr.Slider(
                    minimum=100,
                    maximum=5000,
                    value=2000,
                    step=100,
                    label="æœ€å¤§ç”Ÿæˆé•¿åº¦ - æ§åˆ¶ç”ŸæˆéŸ³é¢‘çš„æœ€å¤§é•¿åº¦"
                )

        # è¾“å‡ºåŒºåŸŸ
        gr.Markdown("### ğŸ“¤ è¾“å‡ºç»“æœ")
        with gr.Row():
            audio_output = gr.Audio(label="ç”Ÿæˆçš„è¯­éŸ³")
            status_output = gr.Textbox(label="çŠ¶æ€", interactive=False)

        # ç‰¹å¾åˆ—è¡¨æ˜¾ç¤ºåŒºåŸŸ
        gr.Markdown("### ğŸ“‹ å·²ä¿å­˜çš„ç‰¹å¾")
        features_output = gr.Textbox(
            label="ç‰¹å¾åˆ—è¡¨",
            placeholder='ç‚¹å‡»"æŸ¥çœ‹æ‰€æœ‰ç‰¹å¾ ID"æŒ‰é’®æŸ¥çœ‹å·²ä¿å­˜çš„ç‰¹å¾...',
            lines=10,
            interactive=False
        )

        # ç»‘å®šäº‹ä»¶
        ref_input_type.change(
            fn=lambda x: {
                upload_col: gr.Column(visible=x == "ä¸Šä¼ æ–‡ä»¶"),
                path_col: gr.Column(visible=x == "è·¯å¾„æ–¹å¼"),
                feat_col: gr.Column(visible=x == "é¢„ç¼–ç ç‰¹å¾")
            },
            inputs=[ref_input_type],
            outputs=[upload_col, path_col, feat_col]
        )

        # æŸ¥çœ‹æ‰€æœ‰ç‰¹å¾
        list_features_btn.click(
            fn=list_ref_features,
            outputs=[features_output]
        )

        # ä¿å­˜å‚è€ƒéŸ³é¢‘ç‰¹å¾
        save_ref_btn.click(
            fn=save_ref_audio,
            inputs=[
                prompt_wav_upload,
                feat_id_input,
                prompt_text
            ],
            outputs=[status_output]
        )

        # ç”Ÿæˆè¯­éŸ³
        generate_btn.click(
            fn=synthesize_tts,
            inputs=[
                text_input,
                prompt_wav_upload,
                prompt_wav_path,
                feat_id_select,
                prompt_text,
                ref_input_type,
                cfg_value,
                inference_timesteps,
                max_len
            ],
            outputs=[audio_output, status_output]
        )

    return tts_interface


async def synthesize_tts(
    text: str,
    prompt_wav_upload: Optional[str],
    prompt_wav_path: Optional[str],
    feat_id: Optional[str],
    prompt_text: Optional[str],
    ref_input_type: str,
    cfg_value: float,
    inference_timesteps: int,
    max_len: int
) -> Tuple[Optional[str], str]:
    """
    æ‰§è¡Œè¯­éŸ³åˆæˆ

    Args:
        text: è¦åˆæˆçš„æ–‡æœ¬
        prompt_wav_upload: ä¸Šä¼ çš„å‚è€ƒéŸ³é¢‘
        prompt_wav_path: å‚è€ƒéŸ³é¢‘è·¯å¾„
        feat_id: é¢„ç¼–ç ç‰¹å¾ ID
        prompt_text: å‚è€ƒæ–‡æœ¬
        ref_input_type: è¾“å…¥æ–¹å¼
        cfg_value: CFGå€¼
        inference_timesteps: æ¨ç†æ­¥æ•°
        max_len: æœ€å¤§ç”Ÿæˆé•¿åº¦

    Returns:
        Tuple[Optional[str], str]: (éŸ³é¢‘è·¯å¾„, çŠ¶æ€æ¶ˆæ¯)
    """
    if not text:
        return None, "è¯·è¾“å…¥è¦åˆæˆçš„æ–‡æœ¬"

    try:
        # ç¡®å®šå‚è€ƒéŸ³é¢‘è·¯å¾„
        prompt_audio = None
        if ref_input_type == "ä¸Šä¼ æ–‡ä»¶" and prompt_wav_upload:
            prompt_audio = prompt_wav_upload
        elif ref_input_type == "è·¯å¾„æ–¹å¼" and prompt_wav_path:
            prompt_audio = prompt_wav_path

        # ä½¿ç”¨ ONNX TTS
        result = await tts_onnx_module.synthesize(
            text=text,
            prompt_wav=prompt_audio,
            prompt_text=prompt_text,
            feat_id=feat_id if ref_input_type == "é¢„ç¼–ç ç‰¹å¾" else None,
            cfg_value=cfg_value,
            min_len=2,
            max_len=max_len,
            timesteps=inference_timesteps
        )

        if result["success"]:
            duration = result.get("duration", 0)
            sample_rate = result.get("sample_rate", 0)
            return result["output_path"], f"è¯­éŸ³åˆæˆæˆåŠŸï¼æ—¶é•¿: {duration:.2f}s, é‡‡æ ·ç‡: {sample_rate}Hz"
        else:
            return None, f"åˆæˆå¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}"

    except Exception as e:
        Logger.error(f"TTS synthesis error: {e}")
        import traceback
        Logger.error(traceback.format_exc())
        return None, f"åˆæˆå¤±è´¥: {str(e)}"


async def save_ref_audio(
    prompt_wav_upload: Optional[str],
    feat_id: str,
    prompt_text: Optional[str]
) -> str:
    """
    ä¿å­˜å‚è€ƒéŸ³é¢‘ç‰¹å¾

    Args:
        prompt_wav_upload: ä¸Šä¼ çš„å‚è€ƒéŸ³é¢‘
        feat_id: ç‰¹å¾ ID
        prompt_text: å‚è€ƒæ–‡æœ¬

    Returns:
        str: çŠ¶æ€æ¶ˆæ¯
    """
    if not prompt_wav_upload:
        return "è¯·å…ˆä¸Šä¼ å‚è€ƒéŸ³é¢‘"

    if not feat_id:
        return "è¯·è¾“å…¥ç‰¹å¾ ID"

    try:
        result = await tts_onnx_module.save_ref_audio(
            feat_id=feat_id,
            prompt_audio_path=prompt_wav_upload,
            prompt_text=prompt_text
        )

        if result["success"]:
            return f"å‚è€ƒéŸ³é¢‘ç‰¹å¾ä¿å­˜æˆåŠŸï¼ç‰¹å¾ ID: {feat_id}, Patches å½¢çŠ¶: {result['patches_shape']}"
        else:
            return f"ä¿å­˜å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}"

    except Exception as e:
        Logger.error(f"Save ref audio error: {e}")
        return f"ä¿å­˜å¤±è´¥: {str(e)}"


def list_ref_features() -> str:
    """
    æŸ¥çœ‹æ‰€æœ‰å·²ä¿å­˜çš„ç‰¹å¾

    Returns:
        str: ç‰¹å¾åˆ—è¡¨æ–‡æœ¬
    """
    try:
        result = tts_onnx_module.list_ref_features()

        if result["success"]:
            if result["count"] == 0:
                return "æš‚æ— å·²ä¿å­˜çš„ç‰¹å¾"
            
            features = result["features"]
            lines = [f"å·²ä¿å­˜ç‰¹å¾æ•°é‡: {result['count']}\n"]
            lines.append("=" * 80)
            
            for feat in features:
                lines.append(f"\nç‰¹å¾ ID: {feat['feat_id']}")
                lines.append(f"å‚è€ƒæ–‡æœ¬: {feat['prompt_text']}")
                lines.append(f"Patch Size: {feat['patch_size']}")
                lines.append(f"æ•°æ®ç±»å‹: {feat['dtype']}")
                lines.append(f"åˆ›å»ºæ—¶é—´: {feat['created_at']}")
                lines.append("-" * 80)
            
            return "\n".join(lines)
        else:
            return f"è·å–ç‰¹å¾åˆ—è¡¨å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}"

    except Exception as e:
        Logger.error(f"List ref features error: {e}")
        return f"è·å–ç‰¹å¾åˆ—è¡¨å¤±è´¥: {str(e)}"